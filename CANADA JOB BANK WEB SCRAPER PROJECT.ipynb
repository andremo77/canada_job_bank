{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa12db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfaca0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Connect to Website and pull data\n",
    "\n",
    "# To find Your User-Agent: https://httpbin.org/get\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\"}\n",
    "\n",
    "#for page in range part 1 (36,950,000 - 36,975,040) Part 2 (36,975,040 - 37,000,000) :\n",
    "pages = np.arange (36950000, 37000001, 1)\n",
    "\n",
    "for page in pages:\n",
    "    \n",
    "    URL = 'https://www.jobbank.gc.ca/jobsearch/jobposting/' + str(page)\n",
    "    sleep(randint(1,10))\n",
    "\n",
    "    #for single page scraping - delete everything before this line except headers and readdress response\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "\n",
    "    #page = page + 1\n",
    "\n",
    "    try:\n",
    "          job_title = soup2.find(property='title').get_text()\n",
    "    except:\n",
    "          job_title = ''\n",
    "\n",
    "    try:\n",
    "        date_posted = soup2.find(property='datePosted').get_text()\n",
    "    except:\n",
    "        date_posted = ''\n",
    "\n",
    "    try:\n",
    "        company = soup2.find(property='hiringOrganization').get_text()\n",
    "    except:\n",
    "        company = ''\n",
    "\n",
    "    try:\n",
    "        address = soup2.find(property='streetAddress').get_text()\n",
    "    except:\n",
    "        address = ''\n",
    "\n",
    "    try:\n",
    "        city = soup2.find(property='addressLocality').get_text()\n",
    "    except:\n",
    "        city = ''\n",
    "\n",
    "    try:\n",
    "        province = soup2.find(property='addressRegion').get_text()\n",
    "    except:\n",
    "        province = ''\n",
    "\n",
    "    try:\n",
    "        wage = soup2.find(property='minValue').get_text()\n",
    "    except:\n",
    "        wage = ''\n",
    "\n",
    "    try:\n",
    "        wage_reference = soup2.find(property='unitText').get_text()\n",
    "    except:\n",
    "        wage_reference = ''\n",
    "\n",
    "    try:\n",
    "        work_hours = soup2.find(property='workHours').get_text()\n",
    "    except:\n",
    "        work_hours = ''\n",
    "\n",
    "    try:\n",
    "        employment_type = soup2.find(property='employmentType').get_text()\n",
    "    except:\n",
    "        employment_type = ''\n",
    "\n",
    "    try:\n",
    "        language = soup2.find(property='qualification').get_text()\n",
    "    except:\n",
    "        language = ''\n",
    "\n",
    "    try:\n",
    "        required_education = soup2.find(property='educationRequirements qualification').get_text()\n",
    "    except:\n",
    "        required_education = ''\n",
    "\n",
    "    try:\n",
    "        required_experience = soup2.find(property='experienceRequirements qualification').get_text()\n",
    "    except:\n",
    "        required_experience = ''\n",
    "\n",
    "    try:\n",
    "        skills = soup2.find(property='experienceRequirements').get_text()\n",
    "    except:\n",
    "        skills = ''\n",
    "\n",
    "    try:\n",
    "        employment_groups = soup2.find(id='employmentGroup').get_text()\n",
    "    except:\n",
    "        employment_groups = ''\n",
    "        \n",
    "    \n",
    "    # Data Cleaning\n",
    "    job_title = job_title.strip()\n",
    "\n",
    "    date_posted = date_posted.strip()[10:]\n",
    "\n",
    "    company = company.strip()\n",
    "\n",
    "    address = address.strip()\n",
    "\n",
    "    city = city.strip()\n",
    "\n",
    "    province = province.strip()\n",
    "\n",
    "    wage = wage.strip()\n",
    "\n",
    "    wage_reference = wage_reference.strip()\n",
    "\n",
    "    work_hours = work_hours.strip()\n",
    "\n",
    "    employment_type = employment_type.strip()\n",
    "\n",
    "    language = language.strip()\n",
    "\n",
    "    required_education = required_education.strip()\n",
    "\n",
    "    required_experience = required_experience.strip()\n",
    "\n",
    "    skills = skills.strip()\n",
    "\n",
    "    employment_groups = employment_groups.strip()[238:] \n",
    "\n",
    "   \n",
    "    print(job_title)\n",
    "    print(date_posted)\n",
    "    print(company)\n",
    "    print(address)\n",
    "    print(city)\n",
    "    print(province)\n",
    "    print(wage)\n",
    "    print(wage_reference)\n",
    "    print(work_hours)\n",
    "    print(employment_type)\n",
    "    print(language)\n",
    "    print(required_education)\n",
    "    print(required_experience)\n",
    "    print(skills)\n",
    "    print(employment_groups)\n",
    "    print(URL)\n",
    "    \n",
    "    \n",
    "    # Timestamp for output to track when data was collected\n",
    "\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    print(today)\n",
    "    \n",
    "    # Data Entry into csv file (prior creation)\n",
    "    #import csv\n",
    "  \n",
    "    header = ['Job Title', 'Date Posted', 'Company', 'Address', 'City', 'Province', 'Wage', 'Wage Reference', 'Work Hours', 'Employment Type', 'Language', 'Required Education', 'Required Experience', 'Skills', 'Employment Groups', 'URL']\n",
    "    values = [job_title, date_posted, company, address, city, province, wage, wage_reference, work_hours, employment_type, language, required_education, required_experience, skills, employment_groups, URL]\n",
    "\n",
    "    with open('CanadaJobBankWebScraperDataset.csv', 'a', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\AM\\CanadaJobBankWebScraperDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bed54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
